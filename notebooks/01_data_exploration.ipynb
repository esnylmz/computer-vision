{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Data Exploration: PianoVAM Dataset\n",
        "\n",
        "This notebook explores the PianoVAM dataset for piano fingering detection.\n",
        "\n",
        "**Contents:**\n",
        "- Load dataset from HuggingFace\n",
        "- Visualize sample videos and frames\n",
        "- Parse and visualize MIDI data\n",
        "- Explore hand skeleton annotations\n",
        "- Understand data quality and characteristics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (run once in Colab)\n",
        "# !pip install -q datasets huggingface_hub opencv-python mido matplotlib seaborn tqdm torchcodec\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Setup for Colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    if not os.path.exists('computer-vision'):\n",
        "        !git clone https://github.com/esnylmz/computer-vision.git\n",
        "    os.chdir('computer-vision')\n",
        "    !pip install -q -e .\n",
        "    # Install torchcodec for audio decoding (required by HuggingFace datasets)\n",
        "    !pip install -q torchcodec\n",
        "else:\n",
        "    # Local development\n",
        "    sys.path.insert(0, '..')\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load PianoVAM Dataset\n",
        "\n",
        "Load the dataset from HuggingFace and explore its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import project modules\n",
        "from src.data.dataset import PianoVAMDataset\n",
        "from src.data.midi_utils import MidiProcessor\n",
        "from src.data.video_utils import VideoProcessor\n",
        "from src.utils.config import load_config\n",
        "\n",
        "# Load configuration\n",
        "config = load_config('configs/default.yaml')\n",
        "print(f\"Project: {config.project_name} v{config.version}\")\n",
        "\n",
        "# =============================================================================\n",
        "# PianoVAM Dataset - Split Information\n",
        "# =============================================================================\n",
        "# Total: 106 samples across 3 splits\n",
        "#   - train: 73 samples\n",
        "#   - validation: 19 samples (column value: 'valid')\n",
        "#   - test: 14 samples\n",
        "#\n",
        "# Our loader filters by the 'split' column in the data.\n",
        "# You can use: 'train', 'validation', 'valid', 'val', 'test'\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nLoading PianoVAM dataset splits...\")\n",
        "print(\"Using streaming=True for efficient loading\")\n",
        "print(\"Limiting to 20 samples per split for exploration...\\n\")\n",
        "\n",
        "# Load train split\n",
        "try:\n",
        "    train_dataset = PianoVAMDataset(split='train', streaming=True, max_samples=20)\n",
        "    print(\"Train dataset ready\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading train dataset: {e}\\n\")\n",
        "    # Try non-streaming as fallback\n",
        "    print(\"Trying non-streaming mode...\")\n",
        "    train_dataset = PianoVAMDataset(split='train', streaming=False, max_samples=20)\n",
        "    print(\"Train dataset ready (non-streaming)\\n\")\n",
        "\n",
        "# Load validation split (accepts 'validation', 'valid', or 'val')\n",
        "# Note: May automatically switch to non-streaming mode if streaming only exposes 'train'\n",
        "val_dataset = PianoVAMDataset(split='validation', streaming=True, max_samples=20)\n",
        "print(\"Validation dataset ready\\n\")\n",
        "\n",
        "# Load test split\n",
        "# Note: May automatically switch to non-streaming mode if streaming only exposes 'train'\n",
        "test_dataset = PianoVAMDataset(split='test', streaming=True, max_samples=20)\n",
        "print(\"Test dataset ready\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"All splits loaded successfully!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify we're actually getting data from each split\n",
        "print(\"Verifying datasets have data...\\n\")\n",
        "\n",
        "# Test train dataset\n",
        "try:\n",
        "    train_sample = next(iter(train_dataset))\n",
        "    print(f\"✓ Train dataset: Found sample ID={train_sample.id}\")\n",
        "except StopIteration:\n",
        "    print(\"✗ Train dataset: EMPTY - no samples found!\")\n",
        "\n",
        "# Test validation dataset  \n",
        "try:\n",
        "    val_sample = next(iter(val_dataset))\n",
        "    print(f\"✓ Validation dataset: Found sample ID={val_sample.id}\")\n",
        "except StopIteration:\n",
        "    print(\"✗ Validation dataset: EMPTY - no samples found!\")\n",
        "\n",
        "# Test test dataset\n",
        "try:\n",
        "    test_sample = next(iter(test_dataset))\n",
        "    print(f\"✓ Test dataset: Found sample ID={test_sample.id}\")\n",
        "except StopIteration:\n",
        "    print(\"✗ Test dataset: EMPTY - no samples found!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Sample exploration:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Explore a sample from train dataset\n",
        "sample = next(iter(train_dataset))\n",
        "\n",
        "print(f\"\\nSample ID: {sample.id}\")\n",
        "print(f\"Composer: {sample.metadata['composer']}\")\n",
        "print(f\"Piece: {sample.metadata['piece']}\")\n",
        "print(f\"Performer: {sample.metadata['performer']}\")\n",
        "print(f\"Skill Level: {sample.metadata['skill_level']}\")\n",
        "print(f\"Duration: {sample.metadata['duration']:.1f}s\")\n",
        "print(f\"\\nKeyboard Corners: {sample.metadata['keyboard_corners']}\")\n",
        "print(f\"\\nFile URLs (these point to HuggingFace, files are downloaded on-demand):\")\n",
        "print(f\"  Video: {sample.video_path[:80]}...\")\n",
        "print(f\"  MIDI: {sample.midi_path[:80]}...\")\n",
        "print(f\"  Skeleton: {sample.skeleton_path[:80]}...\")\n",
        "print(f\"\\nNote: Actual media files are downloaded lazily when you access them.\")\n",
        "print(f\"Use dataset.download_file() or dataset.load_skeleton() to download files.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
