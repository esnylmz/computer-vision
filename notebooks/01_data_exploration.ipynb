{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Data Exploration: PianoVAM Dataset\n",
        "\n",
        "This notebook explores the PianoVAM dataset for piano fingering detection.\n",
        "\n",
        "**Contents:**\n",
        "- Load dataset from HuggingFace\n",
        "- Visualize sample videos and frames\n",
        "- Parse and visualize MIDI data\n",
        "- Explore hand skeleton annotations\n",
        "- Understand data quality and characteristics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (run once in Colab)\n",
        "# !pip install -q datasets huggingface_hub opencv-python mido matplotlib seaborn tqdm\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Setup for Colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    if not os.path.exists('computer-vision'):\n",
        "        !git clone https://github.com/esnylmz/computer-vision.git\n",
        "    os.chdir('computer-vision')\n",
        "    !pip install -q -e .\n",
        "else:\n",
        "    # Local development\n",
        "    sys.path.insert(0, '..')\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load PianoVAM Dataset\n",
        "\n",
        "Load the dataset from HuggingFace and explore its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import project modules\n",
        "from src.data.dataset import PianoVAMDataset\n",
        "from src.data.midi_utils import MidiProcessor\n",
        "from src.data.video_utils import VideoProcessor\n",
        "from src.utils.config import load_config\n",
        "\n",
        "# Load configuration\n",
        "config = load_config('configs/default.yaml')\n",
        "print(f\"Project: {config.project_name} v{config.version}\")\n",
        "\n",
        "# Load the dataset\n",
        "# TIP: Use streaming=True (default) for faster loading and to avoid timeout errors.\n",
        "# Use streaming=False only when you need to index into the dataset by position.\n",
        "# NOTE: The dataset uses 'valid' for validation split, but 'validation' is automatically mapped.\n",
        "# For exploration, we limit to 20 samples to avoid downloading all 107 samples.\n",
        "print(\"\\nLoading PianoVAM dataset with streaming mode...\")\n",
        "print(\"(This avoids timeout issues by not resolving all 432 files upfront)\")\n",
        "print(\"Limiting to 20 samples for quick exploration...\")\n",
        "\n",
        "# Load with streaming=True for reliability (recommended for exploration)\n",
        "# max_samples=20 limits the dataset to first 20 samples for faster exploration\n",
        "train_dataset = PianoVAMDataset(split='train', streaming=True, max_samples=20)\n",
        "print(\"Train dataset loaded (streaming mode - first 20 samples)\")\n",
        "\n",
        "# Note: 'validation' is automatically mapped to 'valid' by the dataset loader\n",
        "val_dataset = PianoVAMDataset(split='valid', streaming=True, max_samples=20)\n",
        "print(\"Validation dataset loaded (streaming mode - first 20 samples)\")\n",
        "\n",
        "test_dataset = PianoVAMDataset(split='test', streaming=True, max_samples=20)\n",
        "print(\"Test dataset loaded (streaming mode - first 20 samples)\")\n",
        "\n",
        "print(\"\\nTo load fully for indexing (may take a few minutes):\")\n",
        "print(\"  dataset = PianoVAMDataset(split='train', streaming=False, timeout=120, max_retries=5)\")\n",
        "print(\"\\nTo load more samples for exploration:\")\n",
        "print(\"  dataset = PianoVAMDataset(split='train', streaming=True, max_samples=100)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore a sample (using iteration for streaming mode)\n",
        "sample = next(iter(train_dataset))\n",
        "\n",
        "print(f\"Sample ID: {sample.id}\")\n",
        "print(f\"Composer: {sample.metadata['composer']}\")\n",
        "print(f\"Piece: {sample.metadata['piece']}\")\n",
        "print(f\"Performer: {sample.metadata['performer']}\")\n",
        "print(f\"Skill Level: {sample.metadata['skill_level']}\")\n",
        "print(f\"Duration: {sample.metadata['duration']:.1f}s\")\n",
        "print(f\"\\nKeyboard Corners: {sample.metadata['keyboard_corners']}\")\n",
        "print(f\"\\nPaths:\")\n",
        "print(f\"  Video: {sample.video_path[:80]}...\")\n",
        "print(f\"  MIDI: {sample.midi_path[:80]}...\")\n",
        "print(f\"  Skeleton: {sample.skeleton_path[:80]}...\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
